{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cda5c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ee375d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38091ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_column\", 100)\n",
    "pd.set_option(\"display.max_row\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7dbb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "640c2196",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"data/English/NewsAggregatorDataset/newsCorpora.csv\",\n",
    "    header=None,\n",
    "    sep=\"\\t\",\n",
    "    index_col=0,\n",
    "    names=[\n",
    "        \"ID\",\n",
    "        \"TITLE\",\n",
    "        \"URL\",\n",
    "        \"PUBLISHER\",\n",
    "        \"CATEGORY\",\n",
    "        \"STORY\",\n",
    "        \"HOSTNAME\",\n",
    "        \"TIMESTAMP\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b2235a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# データの抽出\n",
    "df = df.loc[\n",
    "    df[\"PUBLISHER\"].isin(\n",
    "        [\"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\"]\n",
    "    ),\n",
    "    [\"TITLE\", \"CATEGORY\"],\n",
    "]\n",
    "\n",
    "# データの分割\n",
    "train, valid_test = train_test_split(\n",
    "    df, test_size=0.2, shuffle=True, random_state=0, stratify=df[\"CATEGORY\"]\n",
    ")\n",
    "valid, test = train_test_split(\n",
    "    valid_test,\n",
    "    test_size=0.5,\n",
    "    shuffle=True,\n",
    "    random_state=0,\n",
    "    stratify=valid_test[\"CATEGORY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a259019b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "valid.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49095e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_index2id = dict(zip(train.index, train[\"ID\"]))\n",
    "valid_index2id = dict(zip(valid.index, valid[\"ID\"]))\n",
    "test_index2id = dict(zip(test.index, test[\"ID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7a1c8329",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(\"ID\", inplace=True, axis=1)\n",
    "valid.drop(\"ID\", inplace=True, axis=1)\n",
    "test.drop(\"ID\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "af2a2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasetの定義\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, X, y, tokenizer, max_len):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):  # len(Dataset)で返す値を指定\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):  # Dataset[index]で返す値を指定\n",
    "        text = self.X[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.LongTensor(ids),\n",
    "            \"mask\": torch.LongTensor(mask),\n",
    "            \"labels\": torch.Tensor(self.y[index]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8ba189ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正解ラベルのone-hot化\n",
    "y_train = pd.get_dummies(train, columns=[\"CATEGORY\"])[\n",
    "    [\"CATEGORY_b\", \"CATEGORY_e\", \"CATEGORY_t\", \"CATEGORY_m\"]\n",
    "].values\n",
    "y_valid = pd.get_dummies(valid, columns=[\"CATEGORY\"])[\n",
    "    [\"CATEGORY_b\", \"CATEGORY_e\", \"CATEGORY_t\", \"CATEGORY_m\"]\n",
    "].values\n",
    "y_test = pd.get_dummies(test, columns=[\"CATEGORY\"])[\n",
    "    [\"CATEGORY_b\", \"CATEGORY_e\", \"CATEGORY_t\", \"CATEGORY_m\"]\n",
    "].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "763f292b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10672, 4), (1334, 4), (1334, 4))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9cac08ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ids: tensor([  101,  8945, 26230, 22967, 23283,  5301,  3749,  2005,  6819,  8159,\n",
      "         4305,  1005,  1055, 16420,  2099,   102,     0,     0,     0,     0])\n",
      "mask: tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0])\n",
      "labels: tensor([1., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "# Datasetの作成\n",
    "max_len = 20\n",
    "MODELNAME = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODELNAME)\n",
    "\n",
    "dataset_train = CreateDataset(train[\"TITLE\"], y_train, tokenizer, max_len)\n",
    "dataset_valid = CreateDataset(valid[\"TITLE\"], y_valid, tokenizer, max_len)\n",
    "dataset_test = CreateDataset(test[\"TITLE\"], y_test, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c30cb6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT分類モデルの定義\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, drop_rate, otuput_size):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(MODELNAME, return_dict=False)\n",
    "        self.drop = torch.nn.Dropout(drop_rate)\n",
    "        self.fc = torch.nn.Linear(768, otuput_size)  # BERTの出力に合わせて768次元を指定\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        _, out = self.bert(ids, attention_mask=mask)\n",
    "        out = self.fc(self.drop(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "893fcbbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_loss_f1(model, criterion, loader, device):\n",
    "    \"\"\"損失・正解率を計算\"\"\"\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            # デバイスの指定\n",
    "            ids = data[\"ids\"].to(device)\n",
    "            mask = data[\"mask\"].to(device)\n",
    "            labels = data[\"labels\"].to(device)\n",
    "\n",
    "            # 順伝播\n",
    "            outputs = model(ids, mask)\n",
    "\n",
    "            # 損失計算\n",
    "            loss += criterion(outputs, labels).item()\n",
    "\n",
    "            # 確率計算\n",
    "            prob = torch.sigmoid(outputs)\n",
    "            pred = torch.where(prob > 0.5, 1, 0)\n",
    "\n",
    "            # f1スコア計算\n",
    "            f1 = f1_score(pred.cpu().numpy(), labels.cpu().numpy(), average=\"macro\")\n",
    "\n",
    "    return loss / len(loader), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0f43bc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(\n",
    "        self, patience=5, threshold=0.01, verbose=False, path=\"checkpoint_model.pth\"\n",
    "    ):\n",
    "        \"\"\"引数：最小値の非更新数カウンタ、最小値判定の閾値, 表示設定、モデル格納path\"\"\"\n",
    "\n",
    "        self.patience = patience  # 設定ストップカウンタ\n",
    "        self.threshold = threshold  # 最小値判定の閾値。比率で指定\n",
    "        self.verbose = verbose  # 表示の有無\n",
    "        self.counter = 0  # 現在のカウンタ値\n",
    "        self.early_stop = False  # ストップフラグ\n",
    "        self.val_loss_min = np.Inf  # 前回のベストスコア記憶用\n",
    "        self.path = path  # ベストモデル格納path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss > (1 - self.threshold) * self.val_loss_min:  # ベストスコアを更新できなかった場合\n",
    "            self.counter += 1  # ストップカウンタを+1\n",
    "            if self.verbose:  # 表示を有効にした場合は経過を表示\n",
    "                print(\n",
    "                    f\"EarlyStopping counter: {self.counter} out of {self.patience}\"\n",
    "                )  # 現在のカウンタを表示する\n",
    "            if self.counter >= self.patience:  # 設定カウントを上回ったらストップフラグをTrueに変更\n",
    "                self.early_stop = True\n",
    "                \n",
    "        else:  # ベストスコアを更新した場合\n",
    "            if self.verbose:  # 表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示\n",
    "                print(\n",
    "                    f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "                )\n",
    "            torch.save(model.state_dict(), self.path)  # ベストモデルを指定したpathに保存\n",
    "            \n",
    "            self.val_loss_min = val_loss\n",
    "            self.counter = 0  # ストップカウンタリセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3701a75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    dataset_train,\n",
    "    dataset_valid,\n",
    "    batch_size,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device=None,\n",
    "):\n",
    "    \"\"\"モデルの学習を実行し、損失・正解率のログを返す\"\"\"\n",
    "    # デバイスの指定\n",
    "    model.to(device)\n",
    "\n",
    "    # dataloaderの作成\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_valid = DataLoader(\n",
    "        dataset_valid, batch_size=len(dataset_valid), shuffle=False\n",
    "    )\n",
    "\n",
    "    # 学習\n",
    "    log_train = []\n",
    "    log_valid = []\n",
    "    \n",
    "    earlystopping = EarlyStopping(patience=1, threshold=0.05, verbose=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        # 開始時刻の記録\n",
    "        s_time = time.time()\n",
    "\n",
    "        # 訓練モードに設定\n",
    "        model.train()\n",
    "        for data in dataloader_train:\n",
    "            # デバイスの指定\n",
    "            ids = data[\"ids\"].to(device)\n",
    "            mask = data[\"mask\"].to(device)\n",
    "            labels = data[\"labels\"].to(device)\n",
    "\n",
    "            # 勾配をゼロで初期化\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 順伝播 + 誤差逆伝播 + 重み更新\n",
    "            outputs = model(ids, mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 損失と正解率の算出\n",
    "            loss_train, f1_train = calculate_loss_and_f1(\n",
    "                model, criterion, dataloader_train, device\n",
    "            )\n",
    "            loss_valid, f1_valid = calculate_loss_f1(\n",
    "                model, criterion, dataloader_valid, device\n",
    "            )\n",
    "            log_train.append([loss_train, f1_train])\n",
    "            log_valid.append([loss_valid, f1_valid])\n",
    "    \n",
    "            # 終了時刻の記録\n",
    "            e_time = time.time()\n",
    "            \n",
    "        # ログを出力\n",
    "        print(\n",
    "            f\"epoch: {epoch + 1}, loss_train: {loss_train:.4f}, loss_valid: {loss_valid:.4f}, {(e_time - s_time):.4f}sec\"\n",
    "        )\n",
    "\n",
    "        #★毎エポックearlystoppingの判定をさせる★\n",
    "        earlystopping(loss_valid, model) #callメソッド呼び出し\n",
    "        if earlystopping.early_stop: #ストップフラグがTrueの場合、breakでforループを抜ける\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "\n",
    "    return {\"train\": log_train, \"valid\": log_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93335120",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss_train: 0.5639, loss_valid: 0.5630, 238.7421sec\n",
      "epoch: 1, loss_train: 0.5687, loss_valid: 0.5689, 450.7173sec\n",
      "epoch: 1, loss_train: 0.5047, loss_valid: 0.5047, 666.4386sec\n",
      "epoch: 1, loss_train: 0.4758, loss_valid: 0.4769, 882.5458sec\n",
      "epoch: 1, loss_train: 0.4637, loss_valid: 0.4651, 1113.4808sec\n",
      "epoch: 1, loss_train: 0.4750, loss_valid: 0.4767, 1328.9978sec\n",
      "epoch: 1, loss_train: 0.4666, loss_valid: 0.4694, 1541.7821sec\n",
      "epoch: 1, loss_train: 0.3934, loss_valid: 0.3967, 1748.9946sec\n",
      "epoch: 1, loss_train: 0.4518, loss_valid: 0.4574, 1956.1527sec\n",
      "epoch: 1, loss_train: 0.4012, loss_valid: 0.4079, 2161.3538sec\n",
      "epoch: 1, loss_train: 0.3379, loss_valid: 0.3406, 2370.9865sec\n",
      "epoch: 1, loss_train: 0.3304, loss_valid: 0.3343, 2577.5698sec\n",
      "epoch: 1, loss_train: 0.3169, loss_valid: 0.3230, 2809.0285sec\n",
      "epoch: 1, loss_train: 0.2774, loss_valid: 0.2817, 3035.5554sec\n",
      "epoch: 1, loss_train: 0.2685, loss_valid: 0.2716, 3258.7102sec\n",
      "epoch: 1, loss_train: 0.2839, loss_valid: 0.2882, 3482.1743sec\n",
      "epoch: 1, loss_train: 0.2982, loss_valid: 0.3081, 3717.8327sec\n",
      "epoch: 1, loss_train: 0.2904, loss_valid: 0.3019, 3928.8727sec\n",
      "epoch: 1, loss_train: 0.2516, loss_valid: 0.2586, 4135.7086sec\n",
      "epoch: 1, loss_train: 0.2439, loss_valid: 0.2511, 4346.2361sec\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [56]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# モデルの学習\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m log \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [55]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(dataset_train, dataset_valid, batch_size, model, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 損失と正解率の算出\u001b[39;00m\n\u001b[0;32m---> 48\u001b[0m loss_train, f1_train \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_loss_and_f1\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataloader_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m loss_valid, f1_valid \u001b[38;5;241m=\u001b[39m calculate_loss_f1(\n\u001b[1;32m     52\u001b[0m     model, criterion, dataloader_valid, device\n\u001b[1;32m     53\u001b[0m )\n\u001b[1;32m     54\u001b[0m log_train\u001b[38;5;241m.\u001b[39mappend([loss_train, f1_train])\n",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36mcalculate_loss_and_f1\u001b[0;34m(model, criterion, loader, device)\u001b[0m\n\u001b[1;32m     12\u001b[0m labels \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# 順伝播\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# 損失計算\u001b[39;00m\n\u001b[1;32m     18\u001b[0m loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Input \u001b[0;32mIn [43]\u001b[0m, in \u001b[0;36mBERTClass.forward\u001b[0;34m(self, ids, mask)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, ids, mask):\n\u001b[0;32m---> 10\u001b[0m     _, out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop(out))\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:996\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    987\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m    989\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    990\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    991\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    994\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    995\u001b[0m )\n\u001b[0;32m--> 996\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1004\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1005\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1006\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1007\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1008\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1009\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    576\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mcheckpoint\u001b[38;5;241m.\u001b[39mcheckpoint(\n\u001b[1;32m    577\u001b[0m         create_custom_forward(layer_module),\n\u001b[1;32m    578\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    582\u001b[0m         encoder_attention_mask,\n\u001b[1;32m    583\u001b[0m     )\n\u001b[1;32m    584\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 585\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:472\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    462\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    469\u001b[0m ):\n\u001b[1;32m    470\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[1;32m    471\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 472\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    473\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    474\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    479\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    481\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:402\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    393\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    394\u001b[0m     hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    401\u001b[0m ):\n\u001b[0;32m--> 402\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    411\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[1;32m    412\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1099\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1104\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/transformers/models/bert/modeling_bert.py:342\u001b[0m, in \u001b[0;36mBertSelfAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    338\u001b[0m     attention_probs \u001b[38;5;241m=\u001b[39m attention_probs \u001b[38;5;241m*\u001b[39m head_mask\n\u001b[1;32m    340\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(attention_probs, value_layer)\n\u001b[0;32m--> 342\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m \u001b[43mcontext_layer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpermute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontiguous\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    343\u001b[0m new_context_layer_shape \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39msize()[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m+\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_head_size,)\n\u001b[1;32m    344\u001b[0m context_layer \u001b[38;5;241m=\u001b[39m context_layer\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m*\u001b[39mnew_context_layer_shape)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# パラメータの設定\n",
    "DROP_RATE = 0.4\n",
    "OUTPUT_SIZE = 4\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 4\n",
    "LEARNING_RATE = 2e-4\n",
    "\n",
    "# モデルの定義\n",
    "model = BERTClass(DROP_RATE, OUTPUT_SIZE)\n",
    "\n",
    "# 損失関数の定義\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# オプティマイザの定義\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# デバイスの指定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# モデルの学習\n",
    "log = train_model(\n",
    "    dataset_train,\n",
    "    dataset_valid,\n",
    "    BATCH_SIZE,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    NUM_EPOCHS,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa58e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ログの可視化\n",
    "x_axis = [x for x in range(1, len(log[\"train\"]) + 1)]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].plot(x_axis, np.array(log[\"train\"]).T[0], label=\"train\")\n",
    "ax[0].plot(x_axis, np.array(log[\"valid\"]).T[0], label=\"valid\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"loss\")\n",
    "ax[0].legend()\n",
    "ax[1].plot(x_axis, np.array(log[\"train\"]).T[1], label=\"train\")\n",
    "ax[1].plot(x_axis, np.array(log[\"valid\"]).T[1], label=\"valid\")\n",
    "ax[1].set_xlabel(\"epoch\")\n",
    "ax[1].set_ylabel(\"accuracy\")\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac88682",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction(model, dataset, device):\n",
    "    # Dataloaderの作成\n",
    "    loader = DataLoader(dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "  \n",
    "    prob = []\n",
    "    pred = []\n",
    "    label = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            # デバイスの指定\n",
    "            ids = data[\"ids\"].to(device)\n",
    "            mask = data[\"mask\"].to(device)\n",
    "            label.append(data[\"labels\"].to(device))\n",
    "\n",
    "            # 順伝播 + 予測値の取得 \n",
    "            outputs = model.forward(ids, mask)\n",
    "            prob.append(torch.sigmoid(outputs))\n",
    "            pred.append(torch.where(outputs>0.5, 1, 0))\n",
    "            \n",
    "        pred = torch.cat(pred, dim=0)\n",
    "        prob = torch.cat(prob, dim=0)\n",
    "        label = torch.cat(label, dim=0)\n",
    "        \n",
    "        del model, loader\n",
    "        gc.collect()\n",
    "        return pred, label, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ab3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train, label_train, prob_train = prediction(model, dataset_train, device)\n",
    "pred_valid, label_valid, prob_valid = prediction(model, dataset_valide, device)\n",
    "pred_test, label_test, prob_test = prediction(model, dataset_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db139cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTypes = [\"pred\", \"label\", \"prob\"]\n",
    "trains = [pred_train, label_train, prob_train]\n",
    "valids = [pred_valid, label_valid, prob_valid]\n",
    "tests = [pred_test, label_test, prob_test ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c39c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "trains = dict(zip(dataTypes, [pd.DataFrame(_.cpu().numpy(), columns=train.columns) for _ in trains]))\n",
    "valids = dict(zip(dataTypes, [pd.DataFrame(_.cpu().numpy(), columns=valid.columns) for _ in valids]))\n",
    "tests = dict(zip(dataTypes, [pd.DataFrame(_.cpu().numpy(), columns=test.columns) for _ in tests]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b28d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d3dd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#precision, recallの算出\n",
    "def calculate_pr_rc(pred, label):\n",
    "    pr_rc = []\n",
    "    for col in pred.columns:\n",
    "        pr = precision_score(pred.loc[:, col].values, label.loc[:, col].values)\n",
    "        rc = recall_score(pred.loc[:, col].values, label.loc[:, col].values)\n",
    "        pr_rc.append([pr, rc])\n",
    "    return pr_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc84c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pr_rc = pd.DataFrame(\n",
    "    calculate_pr_rc(tests[\"pred\"], tests[\"label\"]),\n",
    "    index=test.columns,\n",
    "    columns=[\"precision\", \"recall\"]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c761f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(performances):\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    \n",
    "    length = len(performances.columns)\n",
    "    \n",
    "    plt.figure(figsize=(25, 10))\n",
    "    left = np.arange(length)\n",
    "    \n",
    "    plt.bar(left - 0.2, performances.loc[\"precision\", :], width=0.4, label=\"precision\")\n",
    "    plt.bar(left + 0.2, performances.loc[\"recall\", :], width=0.4, label=\"recall\")\n",
    "    plt.xticks(np.arange(length), performances.columns.tolist(), rotation=90)\n",
    "    plt.yticks(np.arange(11)*0.1, np.round(np.arange(11)*0.1, 1))\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.title(\"precision (正確さ) vs recall (カバー率)\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f64868",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(test_pr_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffacdec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244230f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c825420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f51d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c70225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7783898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
