{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cda5c0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T15:56:54.618846Z",
     "start_time": "2022-06-20T15:56:44.069610Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertModel, BertTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee375d86",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:24.220768Z",
     "start_time": "2022-06-20T16:00:24.207037Z"
    }
   },
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38091ea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:24.650726Z",
     "start_time": "2022-06-20T16:00:24.627714Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_column\", 100)\n",
    "pd.set_option(\"display.max_row\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7dbb18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640c2196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:30.751512Z",
     "start_time": "2022-06-20T16:00:25.290508Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/home/jovyan/work/data/NewsAggregatorDataset/newsCorpora.csv\",\n",
    "    header=None,\n",
    "    sep=\"\\t\",\n",
    "    index_col=0,\n",
    "    names=[\n",
    "        \"ID\",\n",
    "        \"TITLE\",\n",
    "        \"URL\",\n",
    "        \"PUBLISHER\",\n",
    "        \"CATEGORY\",\n",
    "        \"STORY\",\n",
    "        \"HOSTNAME\",\n",
    "        \"TIMESTAMP\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b2235a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:31.101257Z",
     "start_time": "2022-06-20T16:00:30.765027Z"
    }
   },
   "outputs": [],
   "source": [
    "# データの抽出\n",
    "df = df.loc[\n",
    "    df[\"PUBLISHER\"].isin(\n",
    "        [\"Reuters\", \"Huffington Post\", \"Businessweek\", \"Contactmusic.com\", \"Daily Mail\"]\n",
    "    ),\n",
    "    [\"TITLE\", \"CATEGORY\"],\n",
    "]\n",
    "\n",
    "# データの分割\n",
    "train, valid_test = train_test_split(\n",
    "    df, test_size=0.2, shuffle=True, random_state=0, stratify=df[\"CATEGORY\"]\n",
    ")\n",
    "valid, test = train_test_split(\n",
    "    valid_test,\n",
    "    test_size=0.5,\n",
    "    shuffle=True,\n",
    "    random_state=0,\n",
    "    stratify=valid_test[\"CATEGORY\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a259019b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:31.132449Z",
     "start_time": "2022-06-20T16:00:31.108365Z"
    }
   },
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)\n",
    "valid.reset_index(inplace=True)\n",
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49095e89",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:31.199377Z",
     "start_time": "2022-06-20T16:00:31.150159Z"
    }
   },
   "outputs": [],
   "source": [
    "train_index2id = dict(zip(train.index, train[\"ID\"]))\n",
    "valid_index2id = dict(zip(valid.index, valid[\"ID\"]))\n",
    "test_index2id = dict(zip(test.index, test[\"ID\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a1c8329",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:35.248131Z",
     "start_time": "2022-06-20T16:00:35.211375Z"
    }
   },
   "outputs": [],
   "source": [
    "train.drop(\"ID\", inplace=True, axis=1)\n",
    "valid.drop(\"ID\", inplace=True, axis=1)\n",
    "test.drop(\"ID\", inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af2a2e29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:37.659273Z",
     "start_time": "2022-06-20T16:00:37.618111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datasetの定義\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, X, y, tokenizer, max_len):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):  # len(Dataset)で返す値を指定\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):  # Dataset[index]で返す値を指定\n",
    "        text = self.X[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            pad_to_max_length=True,\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "\n",
    "        return {\n",
    "            \"ids\": torch.LongTensor(ids),\n",
    "            \"mask\": torch.LongTensor(mask),\n",
    "            \"labels\": torch.Tensor(self.y[index]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba189ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:39.903502Z",
     "start_time": "2022-06-20T16:00:39.807382Z"
    }
   },
   "outputs": [],
   "source": [
    "# 正解ラベルのone-hot化\n",
    "y_train = pd.get_dummies(train, columns=[\"CATEGORY\"])[\n",
    "    [\"CATEGORY_b\", \"CATEGORY_e\", \"CATEGORY_t\", \"CATEGORY_m\"]\n",
    "].values\n",
    "y_valid = pd.get_dummies(valid, columns=[\"CATEGORY\"])[\n",
    "    [\"CATEGORY_b\", \"CATEGORY_e\", \"CATEGORY_t\", \"CATEGORY_m\"]\n",
    "].values\n",
    "y_test = pd.get_dummies(test, columns=[\"CATEGORY\"])[\n",
    "    [\"CATEGORY_b\", \"CATEGORY_e\", \"CATEGORY_t\", \"CATEGORY_m\"]\n",
    "].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "763f292b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:42.346255Z",
     "start_time": "2022-06-20T16:00:42.300803Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10672, 4), (1334, 4), (1334, 4))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape, y_valid.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9cac08ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:50.133530Z",
     "start_time": "2022-06-20T16:00:45.415393Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datasetの作成\n",
    "max_len = 20\n",
    "MODELNAME = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(MODELNAME)\n",
    "\n",
    "dataset_train = CreateDataset(train[\"TITLE\"], y_train, tokenizer, max_len)\n",
    "dataset_valid = CreateDataset(valid[\"TITLE\"], y_valid, tokenizer, max_len)\n",
    "dataset_test = CreateDataset(test[\"TITLE\"], y_test, tokenizer, max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c30cb6de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:50.166263Z",
     "start_time": "2022-06-20T16:00:50.143206Z"
    }
   },
   "outputs": [],
   "source": [
    "# BERT分類モデルの定義\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, drop_rate, otuput_size):\n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(MODELNAME, return_dict=False)\n",
    "        self.drop = torch.nn.Dropout(drop_rate)\n",
    "        self.fc = torch.nn.Linear(768, otuput_size)  # BERTの出力に合わせて768次元を指定\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        _, out = self.bert(ids, attention_mask=mask)\n",
    "        out = self.fc(self.drop(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "893fcbbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:54.112080Z",
     "start_time": "2022-06-20T16:00:54.073952Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_loss_f1(model, criterion, loader, device):\n",
    "    \"\"\"損失・正解率を計算\"\"\"\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            # デバイスの指定\n",
    "            ids = data[\"ids\"].to(device)\n",
    "            mask = data[\"mask\"].to(device)\n",
    "            labels = data[\"labels\"].to(device)\n",
    "\n",
    "            # 順伝播\n",
    "            outputs = model(ids, mask)\n",
    "\n",
    "            # 損失計算\n",
    "            loss += criterion(outputs, labels).item()\n",
    "\n",
    "            # 確率計算\n",
    "            prob = torch.sigmoid(outputs)\n",
    "            pred = torch.where(prob > 0.5, 1, 0)\n",
    "\n",
    "            # f1スコア計算\n",
    "            f1 = f1_score(pred.cpu().numpy(), labels.cpu().numpy(), average=\"macro\")\n",
    "\n",
    "    return loss / len(loader), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f43bc5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:00:55.895086Z",
     "start_time": "2022-06-20T16:00:55.843466Z"
    }
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    def __init__(\n",
    "        self, patience=5, threshold=0.01, verbose=False, path=\"checkpoint_model.pth\"\n",
    "    ):\n",
    "        \"\"\"引数：最小値の非更新数カウンタ、最小値判定の閾値, 表示設定、モデル格納path\"\"\"\n",
    "\n",
    "        self.patience = patience  # 設定ストップカウンタ\n",
    "        self.threshold = threshold  # 最小値判定の閾値。比率で指定\n",
    "        self.verbose = verbose  # 表示の有無\n",
    "        self.counter = 0  # 現在のカウンタ値\n",
    "        self.early_stop = False  # ストップフラグ\n",
    "        self.val_loss_min = np.Inf  # 前回のベストスコア記憶用\n",
    "        self.path = path  # ベストモデル格納path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss > (1 - self.threshold) * self.val_loss_min:  # ベストスコアを更新できなかった場合\n",
    "            self.counter += 1  # ストップカウンタを+1\n",
    "            if self.verbose:  # 表示を有効にした場合は経過を表示\n",
    "                print(\n",
    "                    f\"EarlyStopping counter: {self.counter} out of {self.patience}\"\n",
    "                )  # 現在のカウンタを表示する\n",
    "            if self.counter >= self.patience:  # 設定カウントを上回ったらストップフラグをTrueに変更\n",
    "                self.early_stop = True\n",
    "                \n",
    "        else:  # ベストスコアを更新した場合\n",
    "            if self.verbose:  # 表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示\n",
    "                print(\n",
    "                    f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "                )\n",
    "            torch.save(model.state_dict(), self.path)  # ベストモデルを指定したpathに保存\n",
    "            \n",
    "            self.val_loss_min = val_loss\n",
    "            self.counter = 0  # ストップカウンタリセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3701a75a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T16:01:01.728801Z",
     "start_time": "2022-06-20T16:01:01.681450Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    dataset_train,\n",
    "    dataset_valid,\n",
    "    batch_size,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    num_epochs,\n",
    "    device=None,\n",
    "):\n",
    "    \"\"\"モデルの学習を実行し、損失・正解率のログを返す\"\"\"\n",
    "    # デバイスの指定\n",
    "    model.to(device)\n",
    "\n",
    "    # dataloaderの作成\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "    dataloader_valid = DataLoader(\n",
    "        dataset_valid, batch_size=len(dataset_valid), shuffle=False\n",
    "    )\n",
    "\n",
    "    # 学習\n",
    "    log_train = []\n",
    "    log_valid = []\n",
    "    \n",
    "    earlystopping = EarlyStopping(patience=1, threshold=0.05, verbose=True)\n",
    "    for epoch in range(num_epochs):\n",
    "        # 開始時刻の記録\n",
    "        s_time = time.time()\n",
    "\n",
    "        # 訓練モードに設定\n",
    "        model.train()\n",
    "        for data in dataloader_train:\n",
    "            # デバイスの指定\n",
    "            ids = data[\"ids\"].to(device)\n",
    "            mask = data[\"mask\"].to(device)\n",
    "            labels = data[\"labels\"].to(device)\n",
    "\n",
    "            # 勾配をゼロで初期化\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 順伝播 + 誤差逆伝播 + 重み更新\n",
    "            outputs = model(ids, mask)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # 損失と正解率の算出\n",
    "            loss_train, f1_train = calculate_loss_and_f1(\n",
    "                model, criterion, dataloader_train, device\n",
    "            )\n",
    "            loss_valid, f1_valid = calculate_loss_f1(\n",
    "                model, criterion, dataloader_valid, device\n",
    "            )\n",
    "            log_train.append([loss_train, f1_train])\n",
    "            log_valid.append([loss_valid, f1_valid])\n",
    "    \n",
    "            # 終了時刻の記録\n",
    "            e_time = time.time()\n",
    "            \n",
    "        # ログを出力\n",
    "        print(\n",
    "            f\"epoch: {epoch + 1}, loss_train: {loss_train:.4f}, loss_valid: {loss_valid:.4f}, {(e_time - s_time):.4f}sec\"\n",
    "        )\n",
    "\n",
    "        #★毎エポックearlystoppingの判定をさせる★\n",
    "        earlystopping(loss_valid, model) #callメソッド呼び出し\n",
    "        if earlystopping.early_stop: #ストップフラグがTrueの場合、breakでforループを抜ける\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "\n",
    "    return {\"train\": log_train, \"valid\": log_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93335120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T15:56:04.616781Z",
     "start_time": "2022-06-20T15:32:31.277419Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7c658b217344b3b39e90711bd649c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/420M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# モデルの学習\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m log \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_valid\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(dataset_train, dataset_valid, batch_size, model, criterion, optimizer, num_epochs, device)\u001b[0m\n\u001b[1;32m     43\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels)\n\u001b[1;32m     44\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 45\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# 損失と正解率の算出\u001b[39;00m\n\u001b[1;32m     48\u001b[0m loss_train, f1_train \u001b[38;5;241m=\u001b[39m calculate_loss_and_f1(\n\u001b[1;32m     49\u001b[0m     model, criterion, dataloader_train, device\n\u001b[1;32m     50\u001b[0m )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:88\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m---> 88\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adamw.py:145\u001b[0m, in \u001b[0;36mAdamW.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[38;5;66;03m# record the step after step update\u001b[39;00m\n\u001b[1;32m    143\u001b[0m         state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 145\u001b[0m     \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madamw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    146\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    147\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    148\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m            \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[43m            \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    157\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/_functional.py:155\u001b[0m, in \u001b[0;36madamw\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    151\u001b[0m     denom \u001b[38;5;241m=\u001b[39m (exp_avg_sq\u001b[38;5;241m.\u001b[39msqrt() \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(bias_correction2))\u001b[38;5;241m.\u001b[39madd_(eps)\n\u001b[1;32m    153\u001b[0m step_size \u001b[38;5;241m=\u001b[39m lr \u001b[38;5;241m/\u001b[39m bias_correction1\n\u001b[0;32m--> 155\u001b[0m \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maddcdiv_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexp_avg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdenom\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mstep_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# パラメータの設定\n",
    "DROP_RATE = 0.4\n",
    "OUTPUT_SIZE = 4\n",
    "BATCH_SIZE = 32\n",
    "NUM_EPOCHS = 4\n",
    "LEARNING_RATE = 2e-4\n",
    "\n",
    "# モデルの定義\n",
    "model = BERTClass(DROP_RATE, OUTPUT_SIZE)\n",
    "\n",
    "# 損失関数の定義\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# オプティマイザの定義\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# デバイスの指定\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# モデルの学習\n",
    "log = train_model(\n",
    "    dataset_train,\n",
    "    dataset_valid,\n",
    "    BATCH_SIZE,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    NUM_EPOCHS,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa58e3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T15:56:04.639281Z",
     "start_time": "2022-06-20T15:56:04.639104Z"
    }
   },
   "outputs": [],
   "source": [
    "# ログの可視化\n",
    "x_axis = [x for x in range(1, len(log[\"train\"]) + 1)]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].plot(x_axis, np.array(log[\"train\"]).T[0], label=\"train\")\n",
    "ax[0].plot(x_axis, np.array(log[\"valid\"]).T[0], label=\"valid\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"loss\")\n",
    "ax[0].legend()\n",
    "ax[1].plot(x_axis, np.array(log[\"train\"]).T[1], label=\"train\")\n",
    "ax[1].plot(x_axis, np.array(log[\"valid\"]).T[1], label=\"valid\")\n",
    "ax[1].set_xlabel(\"epoch\")\n",
    "ax[1].set_ylabel(\"accuracy\")\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac88682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T15:56:04.649267Z",
     "start_time": "2022-06-20T15:56:04.649149Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(model, dataset, device):\n",
    "    # Dataloaderの作成\n",
    "    loader = DataLoader(dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "  \n",
    "    prob = []\n",
    "    pred = []\n",
    "    label = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            # デバイスの指定\n",
    "            ids = data[\"ids\"].to(device)\n",
    "            mask = data[\"mask\"].to(device)\n",
    "            label.append(data[\"labels\"].to(device))\n",
    "\n",
    "            # 順伝播 + 予測値の取得 \n",
    "            outputs = model.forward(ids, mask)\n",
    "            prob.append(torch.sigmoid(outputs))\n",
    "            pred.append(torch.where(outputs>0.5, 1, 0))\n",
    "            \n",
    "        pred = torch.cat(pred, dim=0)\n",
    "        prob = torch.cat(prob, dim=0)\n",
    "        label = torch.cat(label, dim=0)\n",
    "        \n",
    "        del model, loader\n",
    "        gc.collect()\n",
    "        return pred, label, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14ab3f5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T15:56:04.657570Z",
     "start_time": "2022-06-20T15:56:04.657487Z"
    }
   },
   "outputs": [],
   "source": [
    "pred_train, label_train, prob_train = prediction(model, dataset_train, device)\n",
    "pred_valid, label_valid, prob_valid = prediction(model, dataset_valide, device)\n",
    "pred_test, label_test, prob_test = prediction(model, dataset_test, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db139cb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T15:56:04.666922Z",
     "start_time": "2022-06-20T15:56:04.666832Z"
    }
   },
   "outputs": [],
   "source": [
    "dataTypes = [\"pred\", \"label\", \"prob\"]\n",
    "trains = [pred_train, label_train, prob_train]\n",
    "valids = [pred_valid, label_valid, prob_valid]\n",
    "tests = [pred_test, label_test, prob_test ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c39c55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T15:56:04.676692Z",
     "start_time": "2022-06-20T15:56:04.676599Z"
    }
   },
   "outputs": [],
   "source": [
    "trains = dict(zip(dataTypes, [pd.DataFrame(_.cpu().numpy(), columns=train.columns) for _ in trains]))\n",
    "valids = dict(zip(dataTypes, [pd.DataFrame(_.cpu().numpy(), columns=valid.columns) for _ in valids]))\n",
    "tests = dict(zip(dataTypes, [pd.DataFrame(_.cpu().numpy(), columns=test.columns) for _ in tests]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291b28d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d3dd7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T15:56:04.685133Z",
     "start_time": "2022-06-20T15:56:04.685045Z"
    }
   },
   "outputs": [],
   "source": [
    "#precision, recallの算出\n",
    "def calculate_pr_rc(pred, label):\n",
    "    pr_rc = []\n",
    "    for col in pred.columns:\n",
    "        pr = precision_score(pred.loc[:, col].values, label.loc[:, col].values)\n",
    "        rc = recall_score(pred.loc[:, col].values, label.loc[:, col].values)\n",
    "        pr_rc.append([pr, rc])\n",
    "    return pr_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc84c7a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T15:56:04.694147Z",
     "start_time": "2022-06-20T15:56:04.694085Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pr_rc = pd.DataFrame(\n",
    "    calculate_pr_rc(tests[\"pred\"], tests[\"label\"]),\n",
    "    index=test.columns,\n",
    "    columns=[\"precision\", \"recall\"]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c761f6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T15:56:04.704302Z",
     "start_time": "2022-06-20T15:56:04.704034Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_performance(performances):\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    \n",
    "    length = len(performances.columns)\n",
    "    \n",
    "    plt.figure(figsize=(25, 10))\n",
    "    left = np.arange(length)\n",
    "    \n",
    "    plt.bar(left - 0.2, performances.loc[\"precision\", :], width=0.4, label=\"precision\")\n",
    "    plt.bar(left + 0.2, performances.loc[\"recall\", :], width=0.4, label=\"recall\")\n",
    "    plt.xticks(np.arange(length), performances.columns.tolist(), rotation=90)\n",
    "    plt.yticks(np.arange(11)*0.1, np.round(np.arange(11)*0.1, 1))\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.title(\"precision (正確さ) vs recall (カバー率)\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f64868",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-20T15:56:04.711461Z",
     "start_time": "2022-06-20T15:56:04.711380Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_performance(test_pr_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffacdec5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244230f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c825420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f51d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c70225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7783898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
