{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72bf1e6f",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cda5c0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:54.628936Z",
     "start_time": "2022-07-18T08:03:52.624168Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38091ea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:54.634123Z",
     "start_time": "2022-07-18T08:03:54.631265Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_column\", 100)\n",
    "pd.set_option(\"display.max_row\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471a1df",
   "metadata": {},
   "source": [
    "# パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b446a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:54.667161Z",
     "start_time": "2022-07-18T08:03:54.636231Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# パラメータの設定\n",
    "MODELNAME=\"bert-base-uncased\"\n",
    "config = AutoConfig.from_pretrained(MODELNAME).to_dict()\n",
    "config[\"drop_rate\"] = 0.4\n",
    "config[\"output_size\"] = 3\n",
    "config[\"train_batch_size\"] = 180\n",
    "config[\"valid_batch_size\"] = 64\n",
    "config[\"num_epochs\"] = 15\n",
    "config[\"learning_rate\"] = 1e-4\n",
    "config[\"model_name\"] = MODELNAME\n",
    "config[\"max_token_len\"] = 128\n",
    "config[\"fold_split\"] = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a9f556",
   "metadata": {},
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "640c2196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:54.800422Z",
     "start_time": "2022-07-18T08:03:54.669104Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    \"/home/jovyan/work/data/train.csv\",\n",
    "    index_col=\"discourse_id\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e5752",
   "metadata": {},
   "source": [
    "## データのラベル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2d318091",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:54.808487Z",
     "start_time": "2022-07-18T08:03:54.803613Z"
    }
   },
   "outputs": [],
   "source": [
    "discourse_types = [\"Lead\", \"Position\", \"Claim\", \"Evidence\", \"Counterclaim\", \"Concluding Statement\", \"Rebuttal\"]\n",
    "target_col_names = [\"Adequate\", \"Effective\", \"Ineffective\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33623ba2",
   "metadata": {},
   "source": [
    "## データ整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14985949",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.030133Z",
     "start_time": "2022-07-18T08:03:54.811237Z"
    }
   },
   "outputs": [],
   "source": [
    "#下処理:discourse_typeとdiscourse_textを結合する\n",
    "sep = AutoTokenizer.from_pretrained(config[\"model_name\"]).sep_token\n",
    "df[\"inputs\"] = df.discourse_type + sep + df.discourse_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b2235a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.068737Z",
     "start_time": "2022-07-18T08:03:55.032380Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# データの分割\n",
    "df_train_valid, df_test = train_test_split(\n",
    "    df, test_size=0.2, shuffle=True, random_state=0, stratify=df[\"discourse_effectiveness\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c041a",
   "metadata": {},
   "source": [
    "## インデックスの割り当て"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6ed5c9f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.075057Z",
     "start_time": "2022-07-18T08:03:55.071119Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#textをtokenizeするクラス(前処理)\n",
    "class tokenize(object):\n",
    "    def __init__(self, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __call__(self, text):\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.LongTensor(input_ids),\n",
    "            \"attention_mask\": torch.LongTensor(attention_mask),\n",
    "            \"token_type_ids\": torch.LongTensor(token_type_ids),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "806f1a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.080637Z",
     "start_time": "2022-07-18T08:03:55.076907Z"
    }
   },
   "outputs": [],
   "source": [
    "# Datasetの定義\n",
    "class CreateDataset(Dataset):\n",
    "    def __init__(self, X, y, transform):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.transform=transform\n",
    "    def __len__(self):  # len(Dataset)で返す値を指定\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, index):  # Dataset[index]で返す値を指定\n",
    "        text = self.X[index]\n",
    "        output_dict = self.transform(text)\n",
    "        output_dict[\"labels\"] = torch.Tensor(self.y[index])\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af2a2e29",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.085995Z",
     "start_time": "2022-07-18T08:03:55.082158Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# Subsetの定義\n",
    "class CreateSubset(Dataset):\n",
    "    def __init__(self, X, y, transform, indices):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.indices = indices\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):  # len(Dataset)で返す値を指定\n",
    "        return len(self.indices)\n",
    "\n",
    "    def __getitem__(self, idx):  # Dataset[index]で返す値を指定\n",
    "        _X = self.X[self.indices[idx]]\n",
    "        output_dict = self.transform(_X)\n",
    "        output_dict[\"labels\"] = torch.Tensor(self.y[self.indices[idx]])\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "670e3dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.091166Z",
     "start_time": "2022-07-18T08:03:55.087553Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# BERT分類モデルの抽象クラス\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.bert = AutoModel.from_pretrained(\n",
    "            MODELNAME, output_hidden_states=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c30cb6de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.097913Z",
     "start_time": "2022-07-18T08:03:55.092655Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# BERT分類モデルの定義(Linear)\n",
    "class BERTLinearClass(BERTClass):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.drop = nn.Dropout(self.config[\"drop_rate\"])\n",
    "        self.fc = nn.Linear(\n",
    "            self.config[\"hidden_size\"], self.config[\"output_size\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        out = self.bert(\n",
    "            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "        )\n",
    "        out = self.drop(out.hidden_states[-1])\n",
    "        out = self.fc(out[:, 0, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f416769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.104833Z",
     "start_time": "2022-07-18T08:03:55.100596Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# BERT分類モデルの定義(Pooling)\n",
    "class BERTPoolingClass(BERTClass):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.drop = nn.Dropout(self.config[\"drop_rate\"])\n",
    "        self.drop = nn.Dropout(self.config[\"drop_rate\"])\n",
    "        self.pooling = nn.AdaptiveMaxPool1d(1)\n",
    "        self.fc = nn.Linear(\n",
    "            self.config[\"hidden_size\"], self.config[\"output_size\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        out = self.bert(\n",
    "            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "        )\n",
    "        out = self.drop(out.hidden_states[-1])\n",
    "        out, _ = out.max(1)\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2103ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.112117Z",
     "start_time": "2022-07-18T08:03:55.107752Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# BERT分類モデルの定義(Couvolution)\n",
    "class BERTConvolutionClass(BERTClass):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.drop = nn.Dropout(self.config[\"drop_rate\"])\n",
    "        self.cnn1 = nn.Conv1d(\n",
    "            self.config[\"hidden_size\"], 256, kernel_size=2, padding=1\n",
    "        )\n",
    "        self.cnn2 = nn.Conv1d(256, 1, kernel_size=2, padding=1)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        out = (\n",
    "            self.bert(\n",
    "                input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "            )\n",
    "            .hidden_states[-1]\n",
    "            .permute(0, 2, 1)\n",
    "        )\n",
    "        out = nn.functional.relu(self.cnn1(out))\n",
    "        out = self.cnn2(out)\n",
    "        out, _ = torch.max(out, 2)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb408e2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.119470Z",
     "start_time": "2022-07-18T08:03:55.113923Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# BERT分類モデルの定義(Concatenate)\n",
    "class BERTConcatenateClass(BERTClass):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.drop = nn.Dropout(self.config[\"drop_rate\"])\n",
    "        self.fc = nn.Linear(\n",
    "            self.config[\"hidden_size\"] * 4, self.config[\"output_size\"]\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        out = self.bert(\n",
    "            input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "        )\n",
    "        out = torch.cat(\n",
    "            [out[\"hidden_states\"][-1 * i][:, 0] for i in range(1, 4 + 1)], dim=1\n",
    "        )  # concatenate\n",
    "        out = self.fc(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "893fcbbb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.126603Z",
     "start_time": "2022-07-18T08:03:55.121448Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def calculate_loss_f1(model, criterion, loader, device):\n",
    "    \"\"\"損失・正解率を計算\"\"\"\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            # デバイスの指定\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            token_type_ids = data[\"token_type_ids\"].to(device)\n",
    "            labels = data[\"labels\"].to(device)\n",
    "\n",
    "            # 順伝播\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "\n",
    "            # 損失計算\n",
    "            loss += criterion(outputs, labels).item()\n",
    "\n",
    "            # 確率計算\n",
    "            prob = torch.sigmoid(outputs)\n",
    "            pred = torch.where(prob > 0.5, 1, 0)\n",
    "\n",
    "            # f1スコア計算\n",
    "            f1 = f1_score(pred.cpu().numpy(), labels.cpu().numpy(), average=\"macro\", zero_division=0)\n",
    "\n",
    "    return loss / len(loader), f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f43bc5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.133972Z",
     "start_time": "2022-07-18T08:03:55.128467Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# EralyStopクラス\n",
    "class EarlyStopping:\n",
    "    def __init__(\n",
    "        self, patience=3, threshold=0.1, verbose=False, path=\"checkpoint_model.pth\"\n",
    "    ):\n",
    "        \"\"\"引数：最小値の非更新数カウンタ、最小値判定の閾値, 表示設定、モデル格納path\"\"\"\n",
    "\n",
    "        self.patience = patience  # 設定ストップカウンタ\n",
    "        self.threshold = threshold  # 最小値判定の閾値。比率で指定\n",
    "        self.verbose = verbose  # 表示の有無\n",
    "        self.counter = 0  # 現在のカウンタ値\n",
    "        self.early_stop = False  # ストップフラグ\n",
    "        self.val_loss_min = np.Inf  # 前回のベストスコア記憶用\n",
    "        self.path = path  # ベストモデル格納path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        if val_loss > (1 - self.threshold) * self.val_loss_min:  # ベストスコアを更新できなかった場合\n",
    "            self.counter += 1  # ストップカウンタを+1\n",
    "            if self.verbose:  # 表示を有効にした場合は経過を表示\n",
    "                print(\n",
    "                    f\"EarlyStopping counter: {self.counter} out of {self.patience}\"\n",
    "                )  # 現在のカウンタを表示する\n",
    "            if self.counter >= self.patience:  # 設定カウントを上回ったらストップフラグをTrueに変更\n",
    "                self.early_stop = True\n",
    "                \n",
    "        else:  # ベストスコアを更新した場合\n",
    "            if self.verbose:  # 表示を有効にした場合は、前回のベストスコアからどれだけ更新したか？を表示\n",
    "                print(\n",
    "                    f\"Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...\"\n",
    "                )\n",
    "            torch.save(model.state_dict(), self.path)  # ベストモデルを指定したpathに保存\n",
    "            \n",
    "            self.val_loss_min = val_loss\n",
    "            self.counter = 0  # ストップカウンタリセット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3701a75a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-18T08:03:55.144562Z",
     "start_time": "2022-07-18T08:03:55.135624Z"
    },
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    X_train_valid,\n",
    "    y_train_valid,\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    config,\n",
    "    device=None,\n",
    "):\n",
    "    \"\"\"モデルの学習を実行し、損失・正解率のログを返す\"\"\"\n",
    "    # デバイスの指定\n",
    "    model.to(device)\n",
    "\n",
    "    # tokenizerの作成\n",
    "    tokenizer = tokenize(\n",
    "        AutoTokenizer.from_pretrained(config[\"model_name\"]), config[\"max_token_len\"]\n",
    "    )\n",
    "    \n",
    "    torch.backends.cudnn.benchmark=True\n",
    "\n",
    "    # 学習\n",
    "    log_train = []\n",
    "    log_valid = []\n",
    "\n",
    "    # Stratified K foldの作成\n",
    "    skf = StratifiedKFold(n_splits=config[\"fold_split\"], random_state=None)\n",
    "    folds = [\n",
    "        (_train_index, _valid_index)\n",
    "        for _train_index, _valid_index in skf.split(X_train_valid, y_train_valid)\n",
    "    ]\n",
    "\n",
    "    # 正解ラベルのone-hot化\n",
    "    y_train_valid = pd.get_dummies(y_train_valid).to_numpy()\n",
    "\n",
    "    earlystopping = EarlyStopping(patience=2, threshold=0.05, verbose=True)\n",
    "    for epoch in range(config[\"num_epochs\"]):\n",
    "        # 開始時刻の記録\n",
    "        s_time = time.time()\n",
    "\n",
    "        # Kfoldsの選択\n",
    "        train_index, valid_index = folds[epoch % config[\"fold_split\"]]\n",
    "\n",
    "        # dataloaderの作成\n",
    "        dataset_train = CreateSubset(\n",
    "            X_train_valid, y_train_valid, tokenizer, train_index\n",
    "        )\n",
    "        dataloader_train = DataLoader(\n",
    "            dataset_train,\n",
    "            batch_size=config[\"train_batch_size\"],\n",
    "            shuffle=True,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "        dataset_valid = CreateSubset(\n",
    "            X_train_valid, y_train_valid, tokenizer, valid_index\n",
    "        )\n",
    "        dataloader_valid = DataLoader(\n",
    "            dataset_valid,\n",
    "            batch_size=config[\"valid_batch_size\"],\n",
    "            shuffle=False,\n",
    "            num_workers=2,\n",
    "            pin_memory=True,\n",
    "        )\n",
    "\n",
    "        # 訓練モードに設定\n",
    "        model.train()\n",
    "        \n",
    "        # Automatic Mixed Precision\n",
    "        scaler = torch.cuda.amp.GradScaler()\n",
    "        \n",
    "        for data in tqdm(dataloader_train):\n",
    "            # デバイスの指定\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            token_type_ids = data[\"token_type_ids\"].to(device)\n",
    "            labels = data[\"labels\"].to(device)\n",
    "\n",
    "            # 勾配をゼロで初期化\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # 順伝播 + 誤差逆伝播 + 重み更新\n",
    "            with torch.cuda.amp.autocast():\n",
    "                outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "                loss = criterion(outputs, labels)\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            # 損失と正解率の算出\n",
    "            loss_train, f1_train = calculate_loss_f1(\n",
    "                model, criterion, dataloader_train, device\n",
    "            )\n",
    "            loss_valid, f1_valid = calculate_loss_f1(\n",
    "                model, criterion, dataloader_valid, device\n",
    "            )\n",
    "            log_train.append([loss_train, f1_train])\n",
    "            log_valid.append([loss_valid, f1_valid])\n",
    "\n",
    "            # 終了時刻の記録\n",
    "            e_time = time.time()\n",
    "\n",
    "        # ログを出力\n",
    "        print(\n",
    "            f\"epoch: {epoch + 1}, loss_train: {loss_train:.4f}, loss_valid: {loss_valid:.4f}, {(e_time - s_time):.4f}sec\"\n",
    "        )\n",
    "\n",
    "        # 毎エポックearlystoppingの判定をさせる\n",
    "        earlystopping(loss_valid, model)  # callメソッド呼び出し\n",
    "        if earlystopping.early_stop:  # ストップフラグがTrueの場合、breakでforループを抜ける\n",
    "            print(\"Early Stopping!\")\n",
    "            break\n",
    "\n",
    "    return {\"train\": log_train, \"valid\": log_valid}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93335120",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-18T08:03:52.468Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      " 13%|█▎        | 17/131 [1:09:33<7:46:45, 245.66s/it]"
     ]
    }
   ],
   "source": [
    "# モデルの定義\n",
    "model = BERTLinearClass(config)\n",
    "\n",
    "# 損失関数の定義\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# オプティマイザの定義\n",
    "optimizer = torch.optim.AdamW(params=model.parameters(), lr=config[\"learning_rate\"])\n",
    "\n",
    "# デバイスの指定\n",
    "device = torch.device(\"cuda:0\")\n",
    "\n",
    "# モデルの学習\n",
    "log = train_model(\n",
    "    df_train_valid[\"discourse_text\"],\n",
    "    df_train_valid[\"discourse_effectiveness\"],\n",
    "    model,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    config,\n",
    "    device=device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baa58e3",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-18T08:03:52.468Z"
    }
   },
   "outputs": [],
   "source": [
    "# ログの可視化\n",
    "x_axis = [x for x in range(1, len(log[\"train\"]) + 1)]\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "ax[0].plot(x_axis, np.array(log[\"train\"]).T[0], label=\"train\")\n",
    "ax[0].plot(x_axis, np.array(log[\"valid\"]).T[0], label=\"valid\")\n",
    "ax[0].set_xlabel(\"epoch\")\n",
    "ax[0].set_ylabel(\"loss\")\n",
    "ax[0].legend()\n",
    "ax[1].plot(x_axis, np.array(log[\"train\"]).T[1], label=\"train\")\n",
    "ax[1].plot(x_axis, np.array(log[\"valid\"]).T[1], label=\"valid\")\n",
    "ax[1].set_xlabel(\"epoch\")\n",
    "ax[1].set_ylabel(\"accuracy\")\n",
    "ax[1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cac08ae",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-18T08:03:52.469Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Datasetの作成\n",
    "tokenizer = tokenize(AutoTokenizer.from_pretrained(config[\"model_name\"]), config[\"max_token_len\"])\n",
    "y_test = pd.get_dummies(df_test[\"discourse_effectiveness\"]).to_numpy()\n",
    "dataset_test = CreateDataset(df_test[\"discourse_text\"], y_test, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac88682",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-18T08:03:52.470Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(model, dataset, device):\n",
    "    # Dataloaderの作成\n",
    "    loader = DataLoader(dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "  \n",
    "    prob = []\n",
    "    pred = []\n",
    "    label = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            # デバイスの指定\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            token_type_ids = data[\"token_type_ids\"].to(device)\n",
    "            label.append(data[\"labels\"].to(device))\n",
    "\n",
    "            # 順伝播 + 予測値の取得 \n",
    "            outputs = model.forward(input_ids, attention_mask, token_type_ids)\n",
    "            prob.append(torch.sigmoid(outputs))\n",
    "            pred.append(torch.where(outputs>0.5, 1, 0))\n",
    "            \n",
    "        pred = torch.cat(pred, dim=0)\n",
    "        prob = torch.cat(prob, dim=0)\n",
    "        label = torch.cat(label, dim=0)\n",
    "        \n",
    "        del model, loader\n",
    "        gc.collect()\n",
    "        return pred, label, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d3dd7c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-18T08:03:52.471Z"
    }
   },
   "outputs": [],
   "source": [
    "#precision, recallの算出\n",
    "def calculate_pr_rc(pred, label):\n",
    "    pr_rc = []\n",
    "    for col in pred.columns:\n",
    "        pr = precision_score(pred.loc[:, col].values, label.loc[:, col].values)\n",
    "        rc = recall_score(pred.loc[:, col].values, label.loc[:, col].values)\n",
    "        pr_rc.append([pr, rc])\n",
    "    return pr_rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc84c7a",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-18T08:03:52.471Z"
    }
   },
   "outputs": [],
   "source": [
    "test_pr_rc = pd.DataFrame(\n",
    "    calculate_pr_rc(tests[\"pred\"], tests[\"label\"]),\n",
    "    index=target_col_names,\n",
    "    columns=[\"precision\", \"recall\"]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c761f6",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-18T08:03:52.472Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_performance(performances):\n",
    "    plt.rcParams[\"font.size\"] = 16\n",
    "    \n",
    "    length = len(performances.columns)\n",
    "    \n",
    "    plt.figure(figsize=(25, 10))\n",
    "    left = np.arange(length)\n",
    "    \n",
    "    plt.bar(left - 0.2, performances.loc[\"precision\", :], width=0.4, label=\"precision\")\n",
    "    plt.bar(left + 0.2, performances.loc[\"recall\", :], width=0.4, label=\"recall\")\n",
    "    plt.xticks(np.arange(length), performances.columns.tolist(), rotation=90)\n",
    "    plt.yticks(np.arange(11)*0.1, np.round(np.arange(11)*0.1, 1))\n",
    "    plt.grid(axis=\"y\")\n",
    "    plt.title(\"precision  vs recall \")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f64868",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-07-18T08:03:52.472Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_performance(test_pr_rc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244230f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c825420",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f51d2e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c70225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7783898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
