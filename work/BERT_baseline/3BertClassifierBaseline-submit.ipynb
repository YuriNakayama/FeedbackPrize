{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72bf1e6f",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cda5c0c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:05:15.955851Z",
     "start_time": "2022-08-10T15:05:13.911651Z"
    }
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import (accuracy_score, f1_score, precision_score,\n",
    "                             recall_score)\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.checkpoint import checkpoint\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoConfig, AutoModel, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38091ea2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:05:15.961324Z",
     "start_time": "2022-08-10T15:05:15.958256Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_column\", 100)\n",
    "pd.set_option(\"display.max_row\", 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471a1df",
   "metadata": {},
   "source": [
    "# パラメータの設定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "780d6dcc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:05:15.992248Z",
     "start_time": "2022-08-10T15:05:15.963301Z"
    }
   },
   "outputs": [],
   "source": [
    "# パラメータの設定\n",
    "MODELNAME=\"microsoft/deberta-v3-base\"\n",
    "config = AutoConfig.from_pretrained(MODELNAME).to_dict()\n",
    "config[\"model_name\"] = MODELNAME\n",
    "config[\"max_token_len\"] = 110\n",
    "config[\"drop_rate\"] = 0.4\n",
    "config[\"output_size\"] = 3\n",
    "config[\"fold_split\"] = 5\n",
    "\n",
    "config[\"train_batch_size\"] = 100\n",
    "config[\"valid_batch_size\"] = 32\n",
    "config[\"num_epochs\"] = 5\n",
    "\n",
    "config[\"learning_rate\"] = 1e-5\n",
    "config[\"lr_T_max\"] = 500\n",
    "config[\"min_lr\"] = 1e-6\n",
    "config[\"weight_decay\"] = 0.005\n",
    "# config[\"warmup_start_value\"] = 0.0\n",
    "# config[\"warmup_end_value\"] = 0.1\n",
    "# config[\"warmup_duration\"] = 3\n",
    "\n",
    "config[\"gradient_checkpoint\"] = True\n",
    "config[\"freezing\"] = True\n",
    "config[\"header_type\"] = \"Concatenate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b446a55",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:05:15.997395Z",
     "start_time": "2022-08-10T15:05:15.994169Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# # パラメータの設定\n",
    "# MODELNAME=\"bert-base-uncased\"\n",
    "# config = AutoConfig.from_pretrained(MODELNAME).to_dict()\n",
    "# config[\"drop_rate\"] = 0.4\n",
    "# config[\"output_size\"] = 3\n",
    "# config[\"train_batch_size\"] = 180\n",
    "# config[\"valid_batch_size\"] = 60\n",
    "# config[\"num_epochs\"] = 1\n",
    "# config[\"learning_rate\"] = 1e-4\n",
    "# config[\"model_name\"] = MODELNAME\n",
    "# config[\"max_token_len\"] = 128\n",
    "# config[\"fold_split\"] = 5\n",
    "# config[\"gradient_checkpoint\"] = True\n",
    "# config[\"freezing\"] = True\n",
    "# config[\"header_type\"] = \"Linear\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050c041a",
   "metadata": {},
   "source": [
    "## definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ed5c9f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:05:16.004506Z",
     "start_time": "2022-08-10T15:05:15.999897Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "#textをtokenizeするクラス(前処理)\n",
    "class tokenize(object):\n",
    "    def __init__(self, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __call__(self, text):\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_len,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        input_ids = inputs[\"input_ids\"]\n",
    "        attention_mask = inputs[\"attention_mask\"]\n",
    "        token_type_ids = inputs[\"token_type_ids\"]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": torch.LongTensor(input_ids),\n",
    "            \"attention_mask\": torch.LongTensor(attention_mask),\n",
    "            \"token_type_ids\": torch.LongTensor(token_type_ids),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "806f1a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:27:36.362001Z",
     "start_time": "2022-08-10T15:27:36.358325Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# DatasetTestの定義\n",
    "class CreateDatasetTest(Dataset):\n",
    "    def __init__(self, X, transform):\n",
    "        self.X = X\n",
    "        self.transform=transform\n",
    "    def __len__(self):  # len(Dataset)で返す値を指定\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):  # Dataset[index]で返す値を指定\n",
    "        text = self.X[index]\n",
    "        output_dict = self.transform(text)\n",
    "        return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce1ed22",
   "metadata": {},
   "source": [
    "## utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ebe9e11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:05:16.016477Z",
     "start_time": "2022-08-10T15:05:16.013335Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def freeze(module):\n",
    "    for parameter in module.parameters():\n",
    "        parameter.require_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e8e5793",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "670e3dc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:05:16.026924Z",
     "start_time": "2022-08-10T15:05:16.018214Z"
    },
    "code_folding": [
     1
    ]
   },
   "outputs": [],
   "source": [
    "# BERT分類モデル\n",
    "class BERTClass(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.bert = AutoModel.from_pretrained(\n",
    "            self.config[\"model_name\"], output_hidden_states=True\n",
    "        )\n",
    "        self.drop = nn.Dropout(self.config[\"drop_rate\"])\n",
    "        if self.config[\"header_type\"] == \"Linear\":\n",
    "            self.fc = nn.Linear(self.config[\"hidden_size\"], self.config[\"output_size\"])\n",
    "        elif self.config[\"header_type\"] == \"Pooling\":\n",
    "            self.pooling = nn.AdaptiveMaxPool1d(1)\n",
    "            self.fc = nn.Linear(\n",
    "                self.config[\"hidden_size\"], self.config[\"output_size\"]\n",
    "            )\n",
    "        elif self.config[\"header_type\"] == \"Couvolution\":\n",
    "            self.cnn1 = nn.Conv1d(\n",
    "                self.config[\"hidden_size\"], 256, kernel_size=2, padding=1\n",
    "            )\n",
    "            self.cnn2 = nn.Conv1d(256, 1, kernel_size=2, padding=1)\n",
    "        elif self.config[\"header_type\"] == \"Concatenate\":\n",
    "            self.fc = nn.Linear(\n",
    "                self.config[\"hidden_size\"] * 4, self.config[\"output_size\"]\n",
    "            )\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        # Gradient Checkpointing\n",
    "        if self.config[\"gradient_checkpoint\"]:\n",
    "            self.bert.gradient_checkpointing_enable()\n",
    "        # Freeze\n",
    "        if self.config[\"freezing\"]:\n",
    "            freeze(self.bert.embeddings)\n",
    "            freeze(self.bert.encoder.layer[:2])\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        x = self.bert(\n",
    "                input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids\n",
    "            )\n",
    "        if self.config[\"header_type\"] == \"Linear\":\n",
    "            x = self.drop(x.hidden_states[-1])\n",
    "            x = self.fc(x[:, 0, :])\n",
    "        elif self.config[\"header_type\"] == \"Pooling\":\n",
    "            x = self.drop(x.hidden_states[-1])\n",
    "            x, _ = x.max(1)\n",
    "            x = self.fc(x)\n",
    "        elif self.config[\"header_type\"] == \"Couvolution\":\n",
    "            x.hidden_states[-1].permute(0, 2, 1)\n",
    "            x = nn.functional.relu(self.cnn1(x))\n",
    "            x = self.cnn2(x)\n",
    "            x, _ = torch.max(x, 2)\n",
    "        elif self.config[\"header_type\"] == \"Concatenate\":\n",
    "            x = torch.cat(\n",
    "                [x[\"hidden_states\"][-1 * i][:, 0] for i in range(1, 4 + 1)], dim=1\n",
    "            )  # concatenate\n",
    "            x = self.fc(x)\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77787de2",
   "metadata": {},
   "source": [
    "# read model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93335120",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:05:21.680252Z",
     "start_time": "2022-08-10T15:05:16.028519Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-base were not used when initializing DebertaV2Model: ['mask_predictions.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BERTClass(\n",
       "  (bert): DebertaV2Model(\n",
       "    (embeddings): DebertaV2Embeddings(\n",
       "      (word_embeddings): Embedding(128100, 768, padding_idx=0)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "      (dropout): StableDropout()\n",
       "    )\n",
       "    (encoder): DebertaV2Encoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (1): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (2): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (3): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (4): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (5): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (6): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (7): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (8): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (9): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (10): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "        (11): DebertaV2Layer(\n",
       "          (attention): DebertaV2Attention(\n",
       "            (self): DisentangledSelfAttention(\n",
       "              (query_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (pos_dropout): StableDropout()\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "            (output): DebertaV2SelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "              (dropout): StableDropout()\n",
       "            )\n",
       "          )\n",
       "          (intermediate): DebertaV2Intermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): DebertaV2Output(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "            (dropout): StableDropout()\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (rel_embeddings): Embedding(512, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-07, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (drop): Dropout(p=0.4, inplace=False)\n",
       "  (fc): Linear(in_features=3072, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# デバイスの指定\n",
    "device = torch.device(\"cuda:0\")\n",
    "# モデルの定義\n",
    "model = BERTClass(config)\n",
    "model.load_state_dict(torch.load(\"/home/jovyan/work/data/checkpoint/checkpoint_model_.pth\"))\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a9f556",
   "metadata": {},
   "source": [
    "# Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "640c2196",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:05:21.688316Z",
     "start_time": "2022-08-10T15:05:21.682446Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\n",
    "    \"/home/jovyan/work/data/test.csv\",\n",
    "    index_col=\"discourse_id\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321e5752",
   "metadata": {},
   "source": [
    "## データのラベル定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2d318091",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:06:40.634540Z",
     "start_time": "2022-08-10T15:06:40.631511Z"
    }
   },
   "outputs": [],
   "source": [
    "discourse_types = [\"Lead\", \"Position\", \"Claim\", \"Evidence\", \"Counterclaim\", \"Concluding Statement\", \"Rebuttal\"]\n",
    "discourse_effectiveness = [\"Ineffective\", \"Adequate\", \"Effective\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33623ba2",
   "metadata": {},
   "source": [
    "## データ整形"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4b2235a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:06:43.267511Z",
     "start_time": "2022-08-10T15:06:42.193742Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:434: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "#下処理:discourse_typeとdiscourse_textを結合する\n",
    "sep = AutoTokenizer.from_pretrained(config[\"model_name\"]).sep_token\n",
    "df_test[\"inputs\"] = df_test.discourse_type + sep + df_test.discourse_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77b5c588",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:06:44.322502Z",
     "start_time": "2022-08-10T15:06:43.270182Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "# Datasetの作成\n",
    "tokenizer = tokenize(AutoTokenizer.from_pretrained(config[\"model_name\"]), config[\"max_token_len\"])\n",
    "dataset = CreateDatasetTest(df_test[\"inputs\"], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ac88682",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:06:44.328716Z",
     "start_time": "2022-08-10T15:06:44.324536Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(model, dataset, device):\n",
    "    # Dataloaderの作成\n",
    "    loader = DataLoader(dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "    model.eval()\n",
    "  \n",
    "    prob = []\n",
    "    with torch.no_grad():\n",
    "        for data in loader:\n",
    "            # デバイスの指定\n",
    "            input_ids = data[\"input_ids\"].to(device)\n",
    "            attention_mask = data[\"attention_mask\"].to(device)\n",
    "            token_type_ids = data[\"token_type_ids\"].to(device)\n",
    "\n",
    "            # 順伝播 + 予測値の取得 \n",
    "            outputs = model.forward(input_ids, attention_mask, token_type_ids)\n",
    "            prob.append(torch.sigmoid(outputs))\n",
    "            \n",
    "        prob = torch.cat(prob, dim=0)\n",
    "        \n",
    "        del model, loader\n",
    "        gc.collect()\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1601c3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:06:44.498857Z",
     "start_time": "2022-08-10T15:06:44.330790Z"
    }
   },
   "outputs": [],
   "source": [
    "prob = prediction(model, dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aca4ae16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:06:44.503853Z",
     "start_time": "2022-08-10T15:06:44.500651Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame(\n",
    "    prob.to(\"cpu\").numpy(), index=df_test.index, columns=discourse_effectiveness\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba2c6e8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:06:44.513986Z",
     "start_time": "2022-08-10T15:06:44.505716Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ineffective</th>\n",
       "      <th>Adequate</th>\n",
       "      <th>Effective</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discourse_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a261b6e14276</th>\n",
       "      <td>0.448783</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>0.033811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5a88900e7dc1</th>\n",
       "      <td>0.688143</td>\n",
       "      <td>0.225496</td>\n",
       "      <td>0.058268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9790d835736b</th>\n",
       "      <td>0.751171</td>\n",
       "      <td>0.117726</td>\n",
       "      <td>0.115207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75ce6d68b67b</th>\n",
       "      <td>0.752210</td>\n",
       "      <td>0.141448</td>\n",
       "      <td>0.098241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93578d946723</th>\n",
       "      <td>0.725802</td>\n",
       "      <td>0.109388</td>\n",
       "      <td>0.120662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2e214524dbe3</th>\n",
       "      <td>0.309576</td>\n",
       "      <td>0.697960</td>\n",
       "      <td>0.021057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84812fc2ab9f</th>\n",
       "      <td>0.284802</td>\n",
       "      <td>0.708937</td>\n",
       "      <td>0.026075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c668ff840720</th>\n",
       "      <td>0.738550</td>\n",
       "      <td>0.141009</td>\n",
       "      <td>0.088919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>739a6d00f44a</th>\n",
       "      <td>0.398511</td>\n",
       "      <td>0.569287</td>\n",
       "      <td>0.032219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bcfae2c9a244</th>\n",
       "      <td>0.403965</td>\n",
       "      <td>0.591043</td>\n",
       "      <td>0.030592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Ineffective  Adequate  Effective\n",
       "discourse_id                                  \n",
       "a261b6e14276     0.448783  0.525860   0.033811\n",
       "5a88900e7dc1     0.688143  0.225496   0.058268\n",
       "9790d835736b     0.751171  0.117726   0.115207\n",
       "75ce6d68b67b     0.752210  0.141448   0.098241\n",
       "93578d946723     0.725802  0.109388   0.120662\n",
       "2e214524dbe3     0.309576  0.697960   0.021057\n",
       "84812fc2ab9f     0.284802  0.708937   0.026075\n",
       "c668ff840720     0.738550  0.141009   0.088919\n",
       "739a6d00f44a     0.398511  0.569287   0.032219\n",
       "bcfae2c9a244     0.403965  0.591043   0.030592"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c8d43ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-10T15:05:24.114762Z",
     "start_time": "2022-08-10T15:05:24.110554Z"
    }
   },
   "outputs": [],
   "source": [
    "submission_df.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
